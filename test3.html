<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Sensor Coverage App</title>
  <style>
    body, html {
      margin: 0;
      padding: 0;
      overflow: hidden; /* Remove scroll bars */
      height: 100%;
      width: 100%;
      background-color: #000;
      font-family: sans-serif;
    }

    #three-canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
    }

    #ui-panel {
      position: absolute;
      top: 10px;
      left: 10px;
      color: #fff;
      background: rgba(0, 0, 0, 0.5);
      padding: 10px;
      border-radius: 4px;
    }

  </style>
</head>
<body>
<!-- UI Panel for sensor selection and instructions -->
<div id="ui-panel">
  <h1>Sensor Coverage App</h1>
  <label for="ceilingHeight">Select Ceiling Height:</label>
  <select id="ceilingHeight">
    <option value="7.5">7.5 ft</option>
    <option value="8.0">8.0 ft</option>
    <option value="9.0">9.0 ft</option>
    <option value="10.0">10.0 ft</option>
    <!-- ... fill in from your coverage table ... -->
  </select>
  <p>Tap on the view to place the sensor.</p>
</div>

<!-- Canvas for the Three.js scene -->
<canvas id="three-canvas"></canvas>

<!-- Optional hidden video element for camera feed -->
<video id="video" autoplay playsinline style="display: none;"></video>

<!-- Three.js (via CDN or local) -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r134/three.min.js"></script>
<!-- Our script -->
<script>
  // Example sensor coverage data, from your table
  // Keyed by ceiling height (ft). The 'width' and 'length' could represent
  // the horizontal coverage extents at floor level, for instance.
  const sensorCoverageData = {
    "7.5": { width: 7.7, length: 9.5 },
    "8.0": { width: 9.2, length: 11.4 },
    "9.0": { width: 10.0, length: 12.3 },
    "10.0": { width: 11.0, length: 13.4 },
    "11.0": { width: 12.3, length: 15.2 },
    "12.0": { width: 13.8, length: 16.5 },
    // ... etc. Fill in or convert to meters if needed
  };

  let scene, camera, renderer;
  let video, videoTexture;
  let sensorMesh = null;
  let coverageMesh = null;

  init();
  animate();

  function init() {
    // Grab DOM elements
    const canvas = document.getElementById("three-canvas");
    const ceilingHeightSelect = document.getElementById("ceilingHeight");
    video = document.getElementById("video");

    // Initialize Three.js
    renderer = new THREE.WebGLRenderer({ canvas, alpha: true });
    renderer.setSize(window.innerWidth, window.innerHeight);

    scene = new THREE.Scene();

    // Create a perspective camera
    camera = new THREE.PerspectiveCamera(
            75, // FOV
            window.innerWidth / window.innerHeight, // Aspect ratio
            0.1, // Near
            1000 // Far
    );
    camera.position.z = 5;

    // Add some lighting
    const ambientLight = new THREE.AmbientLight(0xffffff, 0.5);
    scene.add(ambientLight);

    const dirLight = new THREE.DirectionalLight(0xffffff, 0.8);
    dirLight.position.set(0, 10, 10);
    scene.add(dirLight);

    // Start camera feed
    startCameraFeed();

    // Handle user click/tap to place sensor
    canvas.addEventListener("pointerdown", (event) => {
      placeSensor(event, ceilingHeightSelect.value);
    });

    // Handle window resize
    window.addEventListener("resize", onWindowResize, false);
  }

  function startCameraFeed() {
    // Request camera access
    navigator.mediaDevices
            .getUserMedia({ video: true, audio: false })
            .then((stream) => {
              video.srcObject = stream;
              video.play();

              // Create a video texture for background
              videoTexture = new THREE.VideoTexture(video);

              // Option 1: Set scene background to video
              scene.background = videoTexture;

              // Option 2: Or create a plane in the scene behind everything
              //   const geometry = new THREE.PlaneGeometry(16, 9);
              //   const material = new THREE.MeshBasicMaterial({ map: videoTexture });
              //   const backgroundMesh = new THREE.Mesh(geometry, material);
              //   backgroundMesh.position.z = -5;
              //   scene.add(backgroundMesh);

            })
            .catch((error) => {
              console.error("Error accessing camera:", error);
            });
  }

  function placeSensor(event, ceilingHeight) {
    // Convert screen click to normalized device coordinates
    const rect = renderer.domElement.getBoundingClientRect();
    const x = ((event.clientX - rect.left) / rect.width) * 2 - 1;
    const y = -((event.clientY - rect.top) / rect.height) * 2 + 1;

    // Raycast to find point in 3D
    const mouseVector = new THREE.Vector2(x, y);
    const raycaster = new THREE.Raycaster();
    raycaster.setFromCamera(mouseVector, camera);

    // In this simple example, let's assume there's a ground plane at z=0
    // So we manually find where the ray intersects z=0
    // param t for ray intersection:  origin + t * direction
    // If we want to place the sensor in front of the camera, we might do:
    const t = -camera.position.z / raycaster.ray.direction.z;
    const sensorPos = new THREE.Vector3().copy(raycaster.ray.origin).add(
            raycaster.ray.direction.clone().multiplyScalar(t)
    );

    // If sensorMesh already exists, remove it
    if (sensorMesh) {
      scene.remove(sensorMesh);
      sensorMesh.geometry.dispose();
      sensorMesh.material.dispose();
    }

    // Create a small sphere to represent sensor
    const sensorGeometry = new THREE.SphereGeometry(0.1, 16, 16);
    const sensorMaterial = new THREE.MeshStandardMaterial({ color: 0xff0000 });
    sensorMesh = new THREE.Mesh(sensorGeometry, sensorMaterial);
    sensorMesh.position.copy(sensorPos);
    scene.add(sensorMesh);

    // Now draw coverage area based on the ceiling height
    drawCoverage(sensorPos, ceilingHeight);
  }

  function drawCoverage(sensorPos, ceilingHeight) {
    // Clear old coverage if any
    if (coverageMesh) {
      scene.remove(coverageMesh);
      coverageMesh.geometry.dispose();
      coverageMesh.material.dispose();
    }

    // Example coverage data
    const data = sensorCoverageData[ceilingHeight];
    if (!data) return;

    // Suppose coverage is a cone from the sensor downward.
    // We can interpret 'width' and 'length' as diameters at the floor plane,
    // or treat them as half-angles. For simplicity, let's assume a single radius.
    // Let's use the bigger dimension to approximate radius:
    const radius = Math.max(data.width, data.length) / 2;

    // The height of the cone from the sensor to the floor plane
    // If the sensor is at (x, y, z), let's assume floor is at z=0, so height = sensorPos.z
    // But we must check the actual coordinate system.
    // In this simple example, if camera is at z=5 and we placed sensor at around z=0,
    // we might assume coverage extends in negative z, so let's do something approximate.

    const coverageHeight = 2; // Hard-coded for demonstration
    // If you want it dynamic: coverageHeight = sensorPos.z (if sensor is at z>0)
    // or use the real distance from the sensor to the floor.

    // Create cone geometry
    const coneGeometry = new THREE.ConeGeometry(radius, coverageHeight, 32, 1, true);
    // Flip it upside down if needed
    coneGeometry.rotateX(Math.PI);

    const coneMaterial = new THREE.MeshStandardMaterial({
      color: 0x00ff00,
      opacity: 0.3,
      transparent: true,
      wireframe: false,
    });
    coverageMesh = new THREE.Mesh(coneGeometry, coneMaterial);

    // Position the cone so that its tip is at the sensor
    coverageMesh.position.set(sensorPos.x, sensorPos.y, sensorPos.z - coverageHeight / 2);

    scene.add(coverageMesh);
  }

  function onWindowResize() {
    camera.aspect = window.innerWidth / window.innerHeight;
    camera.updateProjectionMatrix();
    renderer.setSize(window.innerWidth, window.innerHeight);
  }

  function animate() {
    requestAnimationFrame(animate);
    renderer.render(scene, camera);
  }

</script>
</body>
</html>
