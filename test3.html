<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Sensor Coverage App</title>
  <style>
    body, html {
      margin: 0;
      padding: 0;
      overflow: hidden; /* Remove scroll bars */
      height: 100%;
      width: 100%;
      background-color: #000;
      font-family: sans-serif;
    }

    #three-canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
    }

    #ui-panel {
      position: absolute;
      top: 10px;
      left: 10px;
      color: #fff;
      background: rgba(0, 0, 0, 0.5);
      padding: 10px;
      border-radius: 4px;
      z-index: 100;
    }

    label {
      font-weight: bold;
    }

  </style>
</head>
<body>
<!-- UI Panel for sensor selection and instructions -->
<div id="ui-panel">
  <h1>Sensor Coverage App</h1>

  <!-- Camera Selection -->
  <label for="cameraSelect">Select Camera:</label>
  <select id="cameraSelect"></select>

  <br/><br/>

  <!-- Sensor Selection -->
  <label for="ceilingHeight">Select Ceiling Height:</label>
  <select id="ceilingHeight">
    <option value="7.5">7.5 ft</option>
    <option value="8.0">8.0 ft</option>
    <option value="9.0">9.0 ft</option>
    <option value="10.0">10.0 ft</option>
    <!-- ... fill in from your coverage table ... -->
  </select>

  <p>Tap on the view to place the sensor.</p>
</div>

<!-- Canvas for the Three.js scene -->
<canvas id="three-canvas"></canvas>

<!-- Hidden video element for camera feed -->
<video id="video" autoplay playsinline style="display: none;"></video>

<!-- Three.js (via CDN or local) -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r134/three.min.js"></script>
<!-- Our script -->
<script>
  // Example sensor coverage data, from your table
  // Keyed by ceiling height (ft). The 'width' and 'length' represent coverage extents.
  const sensorCoverageData = {
    "7.5": { width: 7.7, length: 9.5 },
    "8.0": { width: 9.2, length: 11.4 },
    "9.0": { width: 10.0, length: 12.3 },
    "10.0": { width: 11.0, length: 13.4 },
    "11.0": { width: 12.3, length: 15.2 },
    "12.0": { width: 13.8, length: 16.5 },
    // ... fill in or convert to meters if needed
  };

  let scene, camera, renderer;
  let video, videoTexture;
  let sensorMesh = null;
  let coverageMesh = null;
  let currentStream = null;

  init();
  animate();

  async function init() {
    // Grab DOM elements
    const canvas = document.getElementById("three-canvas");
    const ceilingHeightSelect = document.getElementById("ceilingHeight");
    const cameraSelect = document.getElementById("cameraSelect");
    video = document.getElementById("video");

    // Initialize Three.js
    renderer = new THREE.WebGLRenderer({ canvas, alpha: true });
    renderer.setSize(window.innerWidth, window.innerHeight);

    scene = new THREE.Scene();

    // Create a perspective camera
    camera = new THREE.PerspectiveCamera(
            75, // FOV
            window.innerWidth / window.innerHeight, // Aspect ratio
            0.1, // Near
            1000 // Far
    );
    camera.position.z = 5;

    // Add some lighting
    const ambientLight = new THREE.AmbientLight(0xffffff, 0.5);
    scene.add(ambientLight);

    const dirLight = new THREE.DirectionalLight(0xffffff, 0.8);
    dirLight.position.set(0, 10, 10);
    scene.add(dirLight);

    // Populate camera selection dropdown
    await populateCameraList(cameraSelect);

    // Start camera feed with the default/first camera
    startCameraFeed(cameraSelect.value);

    // If user changes camera, restart the feed
    cameraSelect.addEventListener("change", () => {
      // Stop any existing stream
      if (currentStream) {
        currentStream.getTracks().forEach(track => track.stop());
      }
      startCameraFeed(cameraSelect.value);
    });

    // Handle user click/tap to place sensor
    canvas.addEventListener("pointerdown", (event) => {
      placeSensor(event, ceilingHeightSelect.value);
    });

    // Handle window resize
    window.addEventListener("resize", onWindowResize, false);
  }

  /**
   * Enumerates available cameras and populates a <select> with them.
   */
  async function populateCameraList(cameraSelect) {
    try {
      const devices = await navigator.mediaDevices.enumerateDevices();
      const videoDevices = devices.filter((d) => d.kind === "videoinput");

      // Clear existing options
      cameraSelect.innerHTML = "";

      // Populate with available cameras
      videoDevices.forEach((device, index) => {
        const option = document.createElement("option");
        option.value = device.deviceId;
        // device.label is only available if the user has already granted permission
        option.text = device.label || `Camera ${index + 1}`;
        cameraSelect.appendChild(option);
      });
    } catch (err) {
      console.error("Error enumerating devices:", err);
    }
  }

  /**
   * Starts the camera feed for a specific deviceId
   */
  function startCameraFeed(deviceId) {
    const constraints = {
      video: {
        deviceId: deviceId ? { exact: deviceId } : undefined,
        // You can add other constraints like facingMode here if desired
      },
      audio: false,
    };

    navigator.mediaDevices
            .getUserMedia(constraints)
            .then((stream) => {
              currentStream = stream;
              video.srcObject = stream;
              video.play();

              // Create a video texture for background
              videoTexture = new THREE.VideoTexture(video);

              // Option 1: Set scene background to video
              scene.background = videoTexture;

              // Option 2: Or create a plane in the scene behind everything
              //   const geometry = new THREE.PlaneGeometry(16, 9);
              //   const material = new THREE.MeshBasicMaterial({ map: videoTexture });
              //   const backgroundMesh = new THREE.Mesh(geometry, material);
              //   backgroundMesh.position.z = -5;
              //   scene.add(backgroundMesh);

            })
            .catch((error) => {
              console.error("Error accessing camera:", error);
            });
  }

  function placeSensor(event, ceilingHeight) {
    // Convert screen click to normalized device coordinates
    const rect = renderer.domElement.getBoundingClientRect();
    const x = ((event.clientX - rect.left) / rect.width) * 2 - 1;
    const y = -((event.clientY - rect.top) / rect.height) * 2 + 1;

    // Raycast to find point in 3D
    const mouseVector = new THREE.Vector2(x, y);
    const raycaster = new THREE.Raycaster();
    raycaster.setFromCamera(mouseVector, camera);

    // In this simple example, let's assume there's a ground plane at z=0
    // So we manually find where the ray intersects z=0
    // param t for ray intersection: origin + t * direction
    const t = -camera.position.z / raycaster.ray.direction.z;
    const sensorPos = new THREE.Vector3().copy(raycaster.ray.origin).add(
            raycaster.ray.direction.clone().multiplyScalar(t)
    );

    // If sensorMesh already exists, remove it
    if (sensorMesh) {
      scene.remove(sensorMesh);
      sensorMesh.geometry.dispose();
      sensorMesh.material.dispose();
    }

    // Create a small sphere to represent sensor
    const sensorGeometry = new THREE.SphereGeometry(0.1, 16, 16);
    const sensorMaterial = new THREE.MeshStandardMaterial({ color: 0xff0000 });
    sensorMesh = new THREE.Mesh(sensorGeometry, sensorMaterial);
    sensorMesh.position.copy(sensorPos);
    scene.add(sensorMesh);

    // Now draw coverage area based on the ceiling height
    drawCoverage(sensorPos, ceilingHeight);
  }

  function drawCoverage(sensorPos, ceilingHeight) {
    // Clear old coverage if any
    if (coverageMesh) {
      scene.remove(coverageMesh);
      coverageMesh.geometry.dispose();
      coverageMesh.material.dispose();
    }

    // Example coverage data
    const data = sensorCoverageData[ceilingHeight];
    if (!data) return;

    // Suppose coverage is a cone from the sensor downward.
    // We'll take the largest dimension as the cone base radius
    const radius = Math.max(data.width, data.length) / 2;

    // Hard-coded coverage height for demonstration
    // In a real scenario, calculate from sensorPos to floor or use actual geometry
    const coverageHeight = 2;

    // Create cone geometry
    const coneGeometry = new THREE.ConeGeometry(radius, coverageHeight, 32, 1, true);
    // Flip it upside down if needed
    coneGeometry.rotateX(Math.PI);

    const coneMaterial = new THREE.MeshStandardMaterial({
      color: 0x00ff00,
      opacity: 0.3,
      transparent: true,
      wireframe: false,
    });
    coverageMesh = new THREE.Mesh(coneGeometry, coneMaterial);

    // Position the cone so that its tip is at the sensor
    coverageMesh.position.set(sensorPos.x, sensorPos.y, sensorPos.z - coverageHeight / 2);

    scene.add(coverageMesh);
  }

  function onWindowResize() {
    camera.aspect = window.innerWidth / window.innerHeight;
    camera.updateProjectionMatrix();
    renderer.setSize(window.innerWidth, window.innerHeight);
  }

  function animate() {
    requestAnimationFrame(animate);
    renderer.render(scene, camera);
  }

</script>
</body>
</html>
