<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Sensor Coverage Visualization</title>
<!--  <link rel="stylesheet" href="styles.css" />-->
  <style>
    /* styles.css */

    /* Container for both video and canvas overlays */
    #app {
      position: relative;
      width: 100%;
      height: 100vh;
      overflow: hidden;
    }

    /* Style for the camera feed video */
    #cameraFeed {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;  /* Maintain aspect ratio and cover the container */
    }

    /* Style for the Three.js canvas overlay */
    #threeCanvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      pointer-events: none; /* Pass clicks through to underlying elements */
    }

  </style>
</head>
<body>
<!-- Main app container -->
<div id="app">
  <!-- Video element for live camera feed -->
  <video id="cameraFeed" autoplay playsinline></video>
  <!-- Canvas element for Three.js 3D visualization -->
  <canvas id="threeCanvas"></canvas>
</div>

<!-- Import main JavaScript file as an ES6 module -->
<script type="module">
  // app.js

  // Import functions from the Three.js module
  import { initThreeScene, updateSensorCoverage } from './threeD.js';

  // Wait for the DOM to fully load before starting
  document.addEventListener('DOMContentLoaded', async () => {
    // Get references to the video and canvas elements
    const video = document.getElementById('cameraFeed');
    const canvas = document.getElementById('threeCanvas');

    // Initialize the Three.js scene on the canvas
    const threeScene = initThreeScene(canvas);

    // Attempt to access the user's camera
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream; // Set the live camera stream as the video source
    } catch (err) {
      console.error('Error accessing the camera:', err);
      alert('Camera access is required for this application.');
      return;
    }

    // Listen for click events on the video element to set the sensor mounting location
    video.addEventListener('click', (event) => {
      // Calculate the click position relative to the video element
      const rect = video.getBoundingClientRect();
      const x = event.clientX - rect.left;
      const y = event.clientY - rect.top;

      console.log('Sensor location (in video coordinates):', { x, y });

      // Example sensor metrics (range in meters, coverage angle in degrees)
      // In a real implementation, these metrics would be provided or updated dynamically.
      const sensorMetrics = {
        range: 10,    // e.g., sensor detection range
        angle: 45     // e.g., sensor coverage angle
      };

      // Update the 3D visualization with the new sensor data and mounting point.
      updateSensorCoverage(threeScene, sensorMetrics, { x, y });
    });
  });

</script>

<script type="module">

</script>
</body>
</html>
